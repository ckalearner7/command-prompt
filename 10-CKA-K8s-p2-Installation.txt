						Building the Kubernetes Cluster
###############
#Release Binaries, Provisioning, and Types of Clusters#
###############
# Материалы:
# https://github.com/kubernetes/kubernetes/releases/tag/v1.15.11
# https://github.com/kubernetes/minikube
# https://kubernetes.io/docs/home/

# Информация о кластере
[root@fas1c ~]# kubectl cluster-info
Kubernetes master is running at https://172.31.17.213:6443
KubeDNS is running at https://172.31.17.213:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy

To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.

[root@fas1c ~]# kubectl config view
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: REDACTED
    server: https://172.31.17.213:6443
  name: kubernetes
contexts:
- context:
    cluster: kubernetes
    user: kubernetes-admin
  name: kubernetes-admin@kubernetes
current-context: kubernetes-admin@kubernetes
kind: Config
preferences: {}
users:
- name: kubernetes-admin
  user:
    client-certificate-data: REDACTED
    client-key-data: REDACTED

[root@fas1c ~]# kubectl api-resources -o wide
NAME                              SHORTNAMES   APIGROUP                       NAMESPACED   KIND                             VERBS
bindings                                                                      true         Binding                          [create]
componentstatuses                 cs                                          false        ComponentStatus                  [get list]
configmaps                        cm                                          true         ConfigMap                        [create delete deletecollection get list patch update watch
...

###############
#Installing Kubernetes Master and Nodes#
###############
# Установка на сервера с Ubuntu 18.04
	# cloud_user@fas1c - master 1
	# cloud_user@fas2c - node 1
	# cloud_user@fas3c - node 2

##### ALL NODES #####

# Шаг 1. Get the Docker gpg key:
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -

# Шаг 2. Add the Docker repository:
sudo add-apt-repository    "deb [arch=amd64] https://download.docker.com/linux/ubuntu \
   $(lsb_release -cs) \
   stable"

# Шаг 3. Get the Kubernetes gpg key:
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -

# Шаг 4. Add the Kubernetes repository:
cat << EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list
deb https://apt.kubernetes.io/ kubernetes-xenial main
EOF

# Шаг 5. Update your packages:
sudo apt-get update

# Шаг 6. Install Docker, kubelet, kubeadm, and kubectl:
sudo apt-get install -y docker-ce=18.06.1~ce~3-0~ubuntu kubelet=1.15.7-00 kubeadm=1.15.7-00 kubectl=1.15.7-00

# Шаг 7. Hold them at the current version (чтобы не было незапланированных обновлений):
sudo apt-mark hold docker-ce kubelet kubeadm kubectl

# Шаг 8. Add the iptables rule to sysctl.conf:
echo "net.bridge.bridge-nf-call-iptables=1" | sudo tee -a /etc/sysctl.conf

# Шаг 9. Enable iptables immediately:
sudo sysctl -p

##### ONLY MASTER #####
# Шаг 10. Initialize the cluster (run only on the master):
sudo kubeadm init --pod-network-cidr=10.244.0.0/16

# Шаг 11. Set up local kubeconfig:
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

# Шаг 12. Apply Flannel CNI network overlay:
kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml

##### ONLY WORKER NODES #####
# Шаг 13. Join the worker nodes to the cluster:
sudo kubeadm join [your unique string from the kubeadm init command]

##### ПРОВЕРКА #####
# Шаг 14. Verify the worker nodes have joined the cluster successfully:
kubectl get nodes

# Шаг 15. Compare this result of the kubectl get nodes command:
cloud_user@fas1c:~$ kubectl get nodes
NAME                           STATUS   ROLES    AGE     VERSION
fas1c.mylabserver.com   Ready    master   4m23s   v1.15.7
fas2c.mylabserver.com   Ready    <none>   118s    v1.15.7
fas3c.mylabserver.com   Ready    <none>   104s    v1.15.7

###############
#Building a Highly Available Kubernetes Cluster#
###############
# Шаг 1. View the pods in the default namespace with a custom view:
# Все служебные поды с сортировкой по нодам
cloud_user@fas1c:~$ kubectl get pods -o custom-columns=POD:metadata.name,NODE:spec.nodeName --sort-by spec.nodeName -n kube-system
POD                                                    NODE
kube-flannel-ds-amd64-cjzgs                            fas1c.mylabserver.com
etcd-fas1c.mylabserver.com                      fas1c.mylabserver.com
kube-apiserver-fas1c.mylabserver.com            fas1c.mylabserver.com
kube-controller-manager-fas1c.mylabserver.com   fas1c.mylabserver.com
kube-scheduler-fas1c.mylabserver.com            fas1c.mylabserver.com
kube-proxy-dh4m7                                       fas1c.mylabserver.com
coredns-5d4dd4b4db-w6t4m                               fas2c.mylabserver.com
coredns-5d4dd4b4db-p6dpw                               fas2c.mylabserver.com
kube-proxy-zclcw                                       fas2c.mylabserver.com
kube-flannel-ds-amd64-5ttr7                            fas2c.mylabserver.com
kube-flannel-ds-amd64-n9q98                            fas3c.mylabserver.com
kube-proxy-vh28q                                       fas3c.mylabserver.com

# Шаг 2. View the kube-scheduler YAML:
cloud_user@fas1c:~$ kubectl get endpoints kube-scheduler -n kube-system -o yaml
apiVersion: v1
kind: Endpoints
metadata:
  annotations:
    control-plane.alpha.kubernetes.io/leader: '{"holderIdentity":"fas1c.mylabserver.com_b31d09ac-6567-47b5-b74d-49310bec1230","leaseDurationSeconds":15,"acquireTime":"2020-03-18T09:17:32Z","renewTime":"2020-03-18T09:39:56Z","leaderTransitions":0}'
  creationTimestamp: "2020-03-18T09:17:32Z"
  name: kube-scheduler
  namespace: kube-system
  resourceVersion: "2454"
  selfLink: /api/v1/namespaces/kube-system/endpoints/kube-scheduler
  uid: 8fa2f6b7-a708-4cf7-830f-16e1df822d6d

# "holderIdentity" показывает активного мастера

##### Дальше не делал #####

# Шаг 3. Create a file called kubeadm-config.yaml
apiVersion: kubeadm.k8s.io/v1beta2
kind: ClusterConfiguration
kubernetesVersion: stable
controlPlaneEndpoint: "LOAD_BALANCER_DNS:LOAD_BALANCER_PORT"
etcd:
    external:
        endpoints:
        - https://ETCD_0_IP:2379
        - https://ETCD_1_IP:2379
        - https://ETCD_2_IP:2379
        caFile: /etc/kubernetes/pki/etcd/ca.crt
        certFile: /etc/kubernetes/pki/apiserver-etcd-client.crt
        keyFile: /etc/kubernetes/pki/apiserver-etcd-client.key

# Шаг 4. Create a stacked etcd topology using kubeadm:
kubeadm init --config=kubeadm-config.yaml

# Шаг 5. Watch as pods are created in the default namespace:
kubectl get pods -n kube-system -w

###############
#Configuring Secure Cluster Communications#
###############
# Шаг 1. View the kube-config:
cloud_user@fas1c:~$ cat .kube/config | more
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN5RENDQWJDZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY=
    server: https://172.31.110.22:6443
  name: kubernetes
contexts:
- context:
    cluster: kubernetes
    user: kubernetes-admin
  name: kubernetes-admin@kubernetes
current-context: kubernetes-admin@kubernetes
kind: Config
preferences: {}
users:
- name: kubernetes-admin
  user:
    client-certificate-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUM4akNDQWRxZ0F3SUJBZ0lJRG80T3l6TTd5Q3d3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhN==

# Шаг 2. View the service account token:
cloud_user@fas1c:~$ kubectl get secrets
NAME                  TYPE                                  DATA   AGE
default-token-qhqkw   kubernetes.io/service-account-token   3      65m

# Шаг 3. Create a new namespace named my-ns:
cloud_user@fas1c:~$ kubectl create ns my-ns
namespace/my-ns created

# Шаг 4. Run the kube-proxy pod in the my-ns namespace:
cloud_user@fas1c:~$ kubectl run test --image=chadmcrowell/kubectl-proxy -n my-ns
kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.
deployment.apps/test created

# Шаг 5. List the pods in the my-ns namespace:
cloud_user@fas1c:~$ kubectl get pods -n my-ns
NAME                    READY   STATUS    RESTARTS   AGE
test-54776597d6-zcqmn   1/1     Running   0          57s

# Шаг 6. Run a shell in the newly created pod:
cloud_user@fas1c:~$ kubectl exec -it test-54776597d6-zcqmn -n my-ns sh
/ #

# Шаг 7. List the services in the namespace via API call:
/ # curl localhost:8001/api/v1/namespaces/my-ns/services
{
  "kind": "Status",
  "apiVersion": "v1",
  "metadata": {

  },
  "status": "Failure",
  "message": "services is forbidden: User \"system:serviceaccount:my-ns:default\" cannot list resource \"services\" in API group \"\" in the namespace \"my-ns\"",
  "reason": "Forbidden",
  "details": {
    "kind": "services"
  },
  "code": 403
}/ #

# Судя по содержанию "message", не хватает прав чтобы посмотреть список сервисов в данном namespace

# Шаг 8. View the token file from within a pod:
}/ # cat /var/run/secrets/kubernetes.io/serviceaccount/token
eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJteS1ucyIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291b/ #

# Шаг 9. List the service account resources in your cluster:
cloud_user@fas1c:~$ kubectl get serviceaccounts
NAME      SECRETS   AGE
default   1         75m

#To prevent unauthorized users from modifying the cluster state, RBAC is used. 
#A service account resource is created for a pod. It determines how it has control over the cluster state. 
#The default service account will not allow you to show the services in a namespace.

###############
#Running End-to-End Tests on Your Cluster#
###############

# O Kubetest: https://github.com/kubernetes/community/blob/master/contributors/devel/sig-testing/e2e-tests.md
# Тестирование кластера
# Шаг 1. Run a simple nginx deployment:
kubectl run nginx --image=nginx
kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.
deployment.apps/nginx created

# Шаг 2. View the deployments in your cluster:
cloud_user@fas1c:~$ kubectl get deployments
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
nginx   1/1     1            1           45s

# Шаг 3. View the pods in the cluster:
cloud_user@fas1c:~$ kubectl get pods
NAME                     READY   STATUS    RESTARTS   AGE
nginx-7bb7cd8db5-ct54k   1/1     Running   0          67s

# Шаг 4. Use port forwarding to access a pod directly:
# Включаем временный проброс порта (с 8001 порта ноды на 80 порт контейнера) 
cloud_user@fas1c:~$ kubectl port-forward nginx-7bb7cd8db5-ct54k 8081:80
Forwarding from 127.0.0.1:8081 -> 80
Forwarding from [::1]:8081 -> 80

# Шаг 5. Get a response from the nginx pod directly:
# Параллельно в новом окне
cloud_user@fas1c:~$ curl --head http://127.0.0.1:8081
HTTP/1.1 200 OK
Server: nginx/1.17.9
Date: Wed, 18 Mar 2020 12:00:33 GMT
Content-Type: text/html
Content-Length: 612
Last-Modified: Tue, 03 Mar 2020 14:32:47 GMT
Connection: keep-alive
ETag: "5e5e6a8f-264"
Accept-Ranges: bytes

cloud_user@fas1c:~$ kubectl port-forward nginx-7bb7cd8db5-ct54k 8081:80
Forwarding from 127.0.0.1:8081 -> 80
Forwarding from [::1]:8081 -> 80
Handling connection for 8081 # Соединение нормальное

# Шаг 6. View the logs from a pod:
cloud_user@fas1c:~$ kubectl logs nginx-7bb7cd8db5-ct54k
127.0.0.1 - - [18/Mar/2020:12:00:33 +0000] "HEAD / HTTP/1.1" 200 0 "-" "curl/7.58.0" "-"

# Шаг 7. Run a command directly from the container (проверяем версию nginx):
cloud_user@fas1c:~$ kubectl exec -it nginx-7bb7cd8db5-ct54k -- nginx -v
nginx version: nginx/1.17.9

# Шаг 8. Create a service by exposing port 80 of the nginx deployment:
cloud_user@fas1c:~$ kubectl get services
NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   168m
cloud_user@fas1c:~$ kubectl expose deployment nginx --port 80 --type NodePort
service/nginx exposed

# Шаг 9. List the services in your cluster:
cloud_user@fas1c:~$ kubectl get services
NAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
kubernetes   ClusterIP   10.96.0.1        <none>        443/TCP        168m
nginx        NodePort    10.110.121.194   <none>        80:31087/TCP   8s

# Шаг 10. Get a response from the service:
cloud_user@fas1c:~$ curl -I localhost:31087
HTTP/1.1 200 OK
Server: nginx/1.17.9
Date: Wed, 18 Mar 2020 12:07:43 GMT
Content-Type: text/html
Content-Length: 612
Last-Modified: Tue, 03 Mar 2020 14:32:47 GMT
Connection: keep-alive
ETag: "5e5e6a8f-264"
Accept-Ranges: bytes

# Шаг 11. List the nodes' status:
cloud_user@fas1c:~$ kubectl get nodes
NAME                           STATUS   ROLES    AGE    VERSION
fas1c.mylabserver.com   Ready    master   171m   v1.15.7
fas2c.mylabserver.com   Ready    <none>   168m   v1.15.7
fas3c.mylabserver.com   Ready    <none>   168m   v1.15.7

# Шаг 12. View detailed information about the nodes:
kubectl describe nodes

# Шаг 13. View detailed information about the pods:
kubectl describe pods